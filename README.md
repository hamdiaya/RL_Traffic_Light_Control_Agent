# ğŸš¦ Traffic Light Control Agent using Deep Reinforcement Learning

This project explores the use of **Deep Reinforcement Learning (DRL)** for intelligent traffic light control at a single four-way intersection, simulated using **SUMO** (Simulation of Urban Mobility).

Our goal was to minimize traffic congestion and vehicle waiting time by training an agent that learns to dynamically adjust traffic signal phases based on real-time conditions.

---

## ğŸ§  Project Overview

We designed and evaluated multiple RL-based traffic control strategies:

### ğŸ”¹ Fixed Duration Control
- Agent selects a traffic phase; duration is fixed (e.g., 30s).
- **Techniques:** DQN, Double DQN, Dueling DQN, PER

### ğŸ”¹ Dynamic Phase Durations
- Agent selects both phase and duration from a discrete set.
- Improves adaptability during varying traffic loads.

### ğŸ”¹ Throughput-Based Control
- Agent switches phases based on vehicle throughput (e.g., % of cars that have passed).
- Yields the best performance in terms of reduced wait times and queue lengths.

---

## ğŸ§ª Techniques Used

- ğŸ§  DQN, Double DQN, Dueling DQN  
- ğŸ§ª Prioritized Experience Replay (PER)  
- ğŸ¯ Curriculum Learning  
- ğŸ“ˆ Layer Normalization, Dropout, Gradient Clipping  
- âš™ï¸ Dynamic Action Spaces (phase + duration or throughput thresholds)  

---

## ğŸ› ï¸ Tools & Frameworks

- ğŸ§® PyTorch for neural network implementation  
- ğŸ›£ï¸ SUMO for traffic simulation  
- ğŸ§ª Python for RL environment integration  

---

## ğŸ“ˆ Results

Our best-performing agent (**throughput-based control**) achieved:

- ğŸš— ~60% reduction in waiting time  
- ğŸš¦ Significant improvement in traffic flow and queue management  
- ğŸ’¡ Adaptive behavior across varied traffic patterns  


---
