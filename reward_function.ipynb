{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76cd6a5a-4dc1-4d67-a48d-247b05dfc263",
   "metadata": {},
   "source": [
    "## simple reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a9b85c-fa71-42c5-a622-568e89d96058",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_reward(self):\n",
    "    # 1. Total Waiting Time (Penalty)\n",
    "    waiting_time_road1 = traci.edge.getWaitingTime(\"road1\")\n",
    "    waiting_time_road2 = traci.edge.getWaitingTime(\"road2\")\n",
    "    total_waiting_time = waiting_time_road1 + waiting_time_road2\n",
    "\n",
    "    # 2. Total Queue Length (Penalty)\n",
    "    queue_length_road1 = traci.edge.getLastStepVehicleNumber(\"road1\")\n",
    "    queue_length_road2 = traci.edge.getLastStepVehicleNumber(\"road2\")\n",
    "    total_queue_length = queue_length_road1 + queue_length_road2\n",
    "\n",
    "    # 3. Throughput (Reward)\n",
    "    throughput = traci.edge.getLastStepVehicleNumber(\"road1\") + traci.edge.getLastStepVehicleNumber(\"road2\")\n",
    "\n",
    "    # 4. Emergency Vehicle Priority (Reward)\n",
    "    emergency_vehicles = 0\n",
    "    for vehicle_id in traci.vehicle.getIDList():\n",
    "        if traci.vehicle.getTypeID(vehicle_id) == \"emergency\":\n",
    "            emergency_vehicles += 1\n",
    "\n",
    "    # 5. Phase Switching Penalty (Penalty)\n",
    "    phase_switching_penalty = 1 if self.last_action != self.current_action else 0\n",
    "\n",
    "    # 6. Fairness Penalty (Penalty)\n",
    "    green_time_road1 = traci.trafficlight.getPhaseDuration(\"intersection\")[0]\n",
    "    green_time_road2 = traci.trafficlight.getPhaseDuration(\"intersection\")[1]\n",
    "    fairness_penalty = abs(green_time_road1 - green_time_road2)\n",
    "\n",
    "    # Combine components with weights\n",
    "    weights = {\n",
    "        \"waiting_time\": -0.1,  # Penalize waiting time\n",
    "        \"queue_length\": -0.05,  # Penalize queue length\n",
    "        \"throughput\": 0.2,      # Reward throughput\n",
    "        \"emergency_vehicles\": 1.0,  # Reward emergency vehicles\n",
    "        \"phase_switching\": -0.2,  # Penalize frequent phase switching\n",
    "        \"fairness\": -0.1  # Penalize unfair green time distribution\n",
    "    }\n",
    "\n",
    "    reward = (\n",
    "        weights[\"waiting_time\"] * total_waiting_time +\n",
    "        weights[\"queue_length\"] * total_queue_length +\n",
    "        weights[\"throughput\"] * throughput +\n",
    "        weights[\"emergency_vehicles\"] * emergency_vehicles +\n",
    "        weights[\"phase_switching\"] * phase_switching_penalty +\n",
    "        weights[\"fairness\"] * fairness_penalty\n",
    "    )\n",
    "\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e91c077-2dd7-4b72-adea-4e3d09751cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Reward: {reward}, Waiting Time: {total_waiting_time}, Queue Length: {total_queue_length}, Throughput: {throughput}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc663cb2-506b-49e8-8d78-59a9ed25e918",
   "metadata": {},
   "source": [
    "## sparse reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76c8b8b-23ac-4435-b282-f27e9ca28895",
   "metadata": {},
   "outputs": [],
   "source": [
    "import traci\n",
    "import numpy as np\n",
    "from dqn_agent import DQNAgent  # Your DQN agent implementation\n",
    "\n",
    "# Define the SUMO environment\n",
    "class SUMOEnv:\n",
    "    def __init__(self, sumo_config):\n",
    "        self.sumo_cmd = [\"sumo-gui\", \"-c\", sumo_config]\n",
    "        self.intersections = [\"intersection1\", \"intersection2\", \"intersection3\", \"intersection4\"]\n",
    "        self.state_dim = len(self.intersections) * 4  # 4 features per intersection\n",
    "        self.action_dim = len(self.intersections)  # 1 action per intersection\n",
    "\n",
    "    def get_state(self):\n",
    "        state = []\n",
    "        for intersection in self.intersections:\n",
    "            queue_length_ns = traci.edge.getLastStepVehicleNumber(f\"{intersection}_ns\")\n",
    "            queue_length_ew = traci.edge.getLastStepVehicleNumber(f\"{intersection}_ew\")\n",
    "            waiting_time_ns = traci.edge.getWaitingTime(f\"{intersection}_ns\")\n",
    "            waiting_time_ew = traci.edge.getWaitingTime(f\"{intersection}_ew\")\n",
    "            current_phase = traci.trafficlight.getPhase(intersection)\n",
    "            throughput = traci.edge.getLastStepVehicleNumber(f\"{intersection}_out\")\n",
    "            state.extend([queue_length_ns, queue_length_ew, waiting_time_ns, waiting_time_ew])\n",
    "        return np.array(state)\n",
    "\n",
    "    def perform_action(self, actions):\n",
    "        for intersection, action in zip(self.intersections, actions):\n",
    "            traci.trafficlight.setPhase(intersection, action)\n",
    "\n",
    "    def calculate_episode_reward(self):\n",
    "        total_waiting_time = 0\n",
    "        total_queue_length = 0\n",
    "        total_throughput = 0\n",
    "        for intersection in self.intersections:\n",
    "            total_waiting_time += traci.edge.getWaitingTime(f\"{intersection}_ns\") + traci.edge.getWaitingTime(f\"{intersection}_ew\")\n",
    "            total_queue_length += traci.edge.getLastStepVehicleNumber(f\"{intersection}_ns\") + traci.edge.getLastStepVehicleNumber(f\"{intersection}_ew\")\n",
    "            total_throughput += traci.edge.getLastStepVehicleNumber(f\"{intersection}_out\")\n",
    "        reward = -(total_waiting_time + total_queue_length) + total_throughput\n",
    "        return reward\n",
    "\n",
    "# Training function\n",
    "def train_agent(agent, env, episodes=1000, episode_length=100, batch_size=32):\n",
    "    for episode in range(episodes):\n",
    "        traci.start(env.sumo_cmd)\n",
    "        states, actions, next_states = [], [], []\n",
    "        total_reward = 0\n",
    "\n",
    "        for step in range(episode_length):\n",
    "            state = env.get_state()\n",
    "            action = agent.act(state)\n",
    "            env.perform_action(action)\n",
    "            next_state = env.get_state()\n",
    "\n",
    "            states.append(state)\n",
    "            actions.append(action)\n",
    "            next_states.append(next_state)\n",
    "\n",
    "            traci.simulationStep()\n",
    "\n",
    "        reward = env.calculate_episode_reward()\n",
    "        for state, action, next_state in zip(states, actions, next_states):\n",
    "            agent.remember(state, action, reward, next_state, done=True)\n",
    "\n",
    "        print(f\"Episode: {episode + 1}, Total Reward: {reward}, Epsilon: {agent.epsilon}\")\n",
    "        traci.close()\n",
    "\n",
    "        if len(agent.memory) > batch_size:\n",
    "            agent.replay(batch_size)\n",
    "\n",
    "    agent.plot_results()\n",
    "\n",
    "# Main function\n",
    "if __name__ == \"__main__\":\n",
    "    sumo_config = \"your_config.sumocfg\"  # Path to your SUMO config file\n",
    "    env = SUMOEnv(sumo_config)\n",
    "    agent = DQNAgent(state_dim=env.state_dim, action_dim=env.action_dim)\n",
    "    train_agent(agent, env)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
